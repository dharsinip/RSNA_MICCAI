{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = []\n",
    "for file in os.listdir('Dataset - Copy (2)/train'):\n",
    "    d = os.path.join('Dataset - Copy (2)/train', file)\n",
    "    if os.path.isdir(d):\n",
    "        path.append(str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    }
   ],
   "source": [
    "print(len(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = []\n",
    "for i in range (len(path)):\n",
    "    for file in os.listdir(path[i] + '/FLAIR'):\n",
    "        x = os.path.join(path[i] + '/FLAIR', file)\n",
    "        image_path.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42301\n"
     ]
    }
   ],
   "source": [
    "print(len(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(image_path)):\n",
    "    dummy = Image.open(image_path[i])\n",
    "    s = dummy.size\n",
    "    tot1 = s[0]*s[1]\n",
    "    matrix = np.array(dummy)\n",
    "    tot2 = np.count_nonzero(matrix == 0)\n",
    "    \n",
    "    if ((tot2/tot1) >= 0.92):\n",
    "        os.remove(image_path[i])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_path)):\n",
    "    try:\n",
    "        image = Image.open(image_path[i])\n",
    "        resized = image.resize((224,224))\n",
    "        resized.save(image_path[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_result = []\n",
    "\n",
    "with open(\"train_labels - Copy.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC) # change contents to floats\n",
    "    for row in reader: # each row is a list\n",
    "        image_result.append(row)\n",
    "        \n",
    "image_result = np.array(image_result)\n",
    "image_result = image_result.astype(int)\n",
    "image_result = image_result.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_files_tmp(src, dest,file):\n",
    "        value=random.randint(1,30000)\n",
    "        full_file_name = src \n",
    "        full_destination=os.path.join(dest,file)\n",
    "        if (os.path.isfile(full_file_name)):\n",
    "            while os.path.exists(full_destination):\n",
    "                full_destination =  full_destination+str(value)+\".png\"\n",
    "            shutil.copy(full_file_name, full_destination)\n",
    "\n",
    "\n",
    "for i in range(0,447):\n",
    "    rand_arr1 = []\n",
    "    rand_arr2 = []\n",
    "    \n",
    "   \n",
    "    if (image_result[i] == 0):\n",
    "        dst_dir = 'C:/Users/DHARSINI/AI PROJECTV/train_mri/plain_tumor'\n",
    "        for file in os.listdir(path[i] + '/FLAIR'):\n",
    "            src=os.path.join(path[i] + '/FLAIR', file)\n",
    "            cp_files_tmp(src, dst_dir,file)\n",
    "    else:\n",
    "        dst_dir = 'C:/Users/DHARSINI/AI PROJECTV/train_mri/miccai_tumor'\n",
    "        for file in os.listdir(path[i] + '/FLAIR'):\n",
    "            src=os.path.join(path[i] + '/FLAIR', file)\n",
    "            cp_files_tmp(src, dst_dir,file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_files_tmp(src, dest,file):\n",
    "        value=random.randint(1,30000)\n",
    "        full_file_name = src \n",
    "        full_destination=os.path.join(dest,file)\n",
    "        if (os.path.isfile(full_file_name)):\n",
    "            while os.path.exists(full_destination):\n",
    "                full_destination =  full_destination+str(value)+\".png\"\n",
    "            shutil.copy(full_file_name, full_destination)\n",
    "\n",
    "\n",
    "for i in range(447,583):\n",
    "    rand_arr1 = []\n",
    "    rand_arr2 = []\n",
    "    \n",
    "   \n",
    "    if (image_result[i] == 0):\n",
    "        dst_dir = 'C:/Users/DHARSINI/AI PROJECTV/test_mri/plain_tumor'\n",
    "        for file in os.listdir(path[i] + '/FLAIR'):\n",
    "            src=os.path.join(path[i] + '/FLAIR', file)\n",
    "            cp_files_tmp(src, dst_dir,file)\n",
    "    else:\n",
    "        dst_dir = 'C:/Users/DHARSINI/AI PROJECTV/test_mri/miccai_tumor'\n",
    "        for file in os.listdir(path[i] + '/FLAIR'):\n",
    "            src=os.path.join(path[i] + '/FLAIR', file)\n",
    "            cp_files_tmp(src, dst_dir,file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=ImageDataGenerator(rescale=1/255)\n",
    "test=ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30484 images belonging to 2 classes.\n",
      "Found 11817 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset=train.flow_from_directory('C:/Users/DHARSINI/AI PROJECTV/train_mri/',\n",
    "                                       target_size=(224,224),\n",
    "                                       class_mode='binary')\n",
    "test_dataset=test.flow_from_directory('C:/Users/DHARSINI/AI PROJECTV/test_mri/',\n",
    "                                       target_size=(224,224),\n",
    "                                       class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'miccai_tumor': 0, 'plain_tumor': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'miccai_tumor': 0, 'plain_tumor': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation='relu'),\n",
    "                                  tf.keras.layers.MaxPool2D(2,2),\n",
    "                                  \n",
    "                                  tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "                                  tf.keras.layers.MaxPool2D(2,2),\n",
    "    \n",
    "                                  tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "                                  tf.keras.layers.MaxPool2D(2,2),\n",
    "                                  \n",
    "                                  tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "                                  tf.keras.layers.MaxPool2D(2,2),\n",
    "                                  \n",
    "                                  \n",
    "                                  tf.keras.layers.Flatten(),\n",
    "#                                   tf.keras.layers.Dense(12544,activation='relu'),\n",
    "#                                   tf.keras.layers.Dense(3136,activation='relu'),\n",
    "                                  tf.keras.layers.Dense(784,activation='relu'),\n",
    "                                  tf.keras.layers.Dense(196,activation='relu'),\n",
    "                                  tf.keras.layers.Dense(1,activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "953/953 [==============================] - 932s 977ms/step - loss: 0.6010 - accuracy: 0.6661\n",
      "Epoch 2/10\n",
      "953/953 [==============================] - 862s 904ms/step - loss: 0.3620 - accuracy: 0.8199\n",
      "Epoch 3/10\n",
      "953/953 [==============================] - 1508s 2s/step - loss: 0.1845 - accuracy: 0.9147\n",
      "Epoch 4/10\n",
      "953/953 [==============================] - 855s 897ms/step - loss: 0.1078 - accuracy: 0.9549\n",
      "Epoch 5/10\n",
      "953/953 [==============================] - 1215s 1s/step - loss: 0.0665 - accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "953/953 [==============================] - 1232s 1s/step - loss: 0.0465 - accuracy: 0.9833\n",
      "Epoch 7/10\n",
      "953/953 [==============================] - 1345s 1s/step - loss: 0.0339 - accuracy: 0.9884\n",
      "Epoch 8/10\n",
      "953/953 [==============================] - 1360s 1s/step - loss: 0.0296 - accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "953/953 [==============================] - 958s 1s/step - loss: 0.0242 - accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "953/953 [==============================] - 853s 895ms/step - loss: 0.0212 - accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "model_fit=model.fit(train_dataset,\n",
    "                   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 101s 272ms/step - loss: 5.0152 - accuracy: 0.5305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.015197277069092, 0.5305069088935852]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
